{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85d6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pipwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90845456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pipwin install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c36c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11003f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import pyaudio\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c42625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "   \n",
    "    rows,cols = array.shape\n",
    "    print(rows)\n",
    "    print(cols)\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "              first =0\n",
    "            else:\n",
    "              first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd6c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio,rate):  \n",
    "       \n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    print(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84e8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def record_audio_train():\n",
    "#     Name =(input(\"Please Enter Your Name:\"))\n",
    "#     for count in range(5):\n",
    "#         FORMAT = pyaudio.paInt16\n",
    "#         CHANNELS = 1\n",
    "#         RATE = 44100\n",
    "#         CHUNK = 512\n",
    "#         RECORD_SECONDS = 10\n",
    "#         device_index = 2\n",
    "#         audio = pyaudio.PyAudio()\n",
    "#         print(\"----------------------record device list---------------------\")\n",
    "#         info = audio.get_host_api_info_by_index(0)\n",
    "#         numdevices = info.get('deviceCount')\n",
    "#         for i in range(0, numdevices):\n",
    "#             if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "#                 print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "#         print(\"-------------------------------------------------------------\")\n",
    "#         index = int(input())\n",
    "#         print(\"recording via index \"+str(index))\n",
    "#         stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "#                             rate=RATE, input=True,input_device_index = index,\n",
    "#                             frames_per_buffer=CHUNK)\n",
    "#         print (\"recording started\")\n",
    "#         Recordframes = []\n",
    "#         for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "#             data = stream.read(CHUNK)\n",
    "#             Recordframes.append(data)\n",
    "#         print (\"recording stopped\")\n",
    "#         stream.stop_stream()\n",
    "#         stream.close()\n",
    "#         audio.terminate()\n",
    "#         OUTPUT_FILENAME=Name+\"-sample\"+str(count)+\".wav\"\n",
    "#         WAVE_OUTPUT_FILENAME=os.path.join(\"training_set\",OUTPUT_FILENAME)\n",
    "#         trainedfilelist = open(\"training_set_addition.txt\", 'a')\n",
    "#         trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "#         waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#         waveFile.setnchannels(CHANNELS)\n",
    "#         waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#         waveFile.setframerate(RATE)\n",
    "#         waveFile.writeframes(b''.join(Recordframes))\n",
    "#         waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e116f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def record_audio_test():\n",
    "#     FORMAT = pyaudio.paInt16\n",
    "#     CHANNELS = 1\n",
    "#     RATE = 44100\n",
    "#     CHUNK = 512\n",
    "#     RECORD_SECONDS = 10\n",
    "#     device_index = 2\n",
    "#     audio = pyaudio.PyAudio()\n",
    "#     print(\"----------------------record device list---------------------\")\n",
    "#     info = audio.get_host_api_info_by_index(0)\n",
    "#     numdevices = info.get('deviceCount')\n",
    "#     for i in range(0, numdevices):\n",
    "#         if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "#             print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "#     print(\"-------------------------------------------------------------\")\n",
    "#     index = int(input())\n",
    "#     print(\"recording via index \"+str(index))\n",
    "#     stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "#                         rate=RATE, input=True,input_device_index = index,\n",
    "#                         frames_per_buffer=CHUNK)\n",
    "#     print (\"recording started\")\n",
    "#     Recordframes = []\n",
    "#     for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "#         data = stream.read(CHUNK)\n",
    "#         Recordframes.append(data)\n",
    "#     print (\"recording stopped\")\n",
    "#     stream.stop_stream()\n",
    "#     stream.close()\n",
    "#     audio.terminate()\n",
    "#     OUTPUT_FILENAME=\"sample.wav\"\n",
    "#     WAVE_OUTPUT_FILENAME=os.path.join(\"testing_set\",OUTPUT_FILENAME)\n",
    "#     trainedfilelist = open(\"testing_set_addition.txt\", 'a')\n",
    "#     trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "#     waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#     waveFile.setnchannels(CHANNELS)\n",
    "#     waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#     waveFile.setframerate(RATE)\n",
    "#     waveFile.writeframes(b''.join(Recordframes))\n",
    "#     waveFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47712e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def record_audio_test():\n",
    "    old_path=input('Enter the path of your audio that you want to test:')\n",
    "    new_path=r\"C:\\\\Users\\\\Swati\\\\Desktop\\\\Cloud strats\\\\Gmm model\\\\testing_set\"\n",
    "    shutil.move(old_path,new_path)\n",
    "    for filename in os.listdir(r\"C:\\Users\\Swati\\Desktop\\Cloud strats\\Gmm model\\testing_set\"):\n",
    "        testfilelist = open(\"testing_set_addition.txt\", 'a')\n",
    "        testfilelist.write(filename+\"\\n\")\n",
    "        testfilelist.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3311717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def record_audio_train():\n",
    "#         FORMAT = pyaudio.paInt16\n",
    "#         CHANNELS = 1\n",
    "#         RATE = 44100\n",
    "#         CHUNK = 512\n",
    "#         RECORD_SECONDS = 10\n",
    "#         device_index = 2\n",
    "#         for dirname, _, filenames in os.walk(\"C:\\\\Users\\\\Acer\\\\Cloudstrat\\\\noise\"):\n",
    "#             for filename in filenames:\n",
    "#                 count=1\n",
    "#                 =os.path.join(dirname, filename)\n",
    "#                 OUTPUT_FILENAME=filename[:-4]+\".wav\"\n",
    "#                 WAVE_OUTPUT_FILENAME=os.path.join(\"training_set\",OUTPUT_FILENAME)\n",
    "#                 trainedfilelist = open(\"training_set_addition.txt\", 'a')\n",
    "#                 trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "#                 waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#                 waveFile.setnchannels(CHANNELS)\n",
    "#                 waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#                 waveFile.setframerate(RATE)\n",
    "#                 waveFile.writeframes(b''.join(Recordframes))\n",
    "#                 waveFile.close()\n",
    "#                 count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b829d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMAT = pyaudio.paInt16\n",
    "# CHANNELS = 1\n",
    "# RATE = 44100\n",
    "# CHUNK = 512\n",
    "# RECORD_SECONDS = 10\n",
    "# device_index = 2\n",
    "# for dirname, _, filenames in os.walk(\"C:\\\\Users\\\\Acer\\\\Cloudstrat\\\\Speaker Detection-GMM\\\\training_set\"):\n",
    "#     for filename in filenames:\n",
    "#                 audio=os.path.join(dirname, filename)\n",
    "#                 audio = pyaudio.PyAudio()\n",
    "#                 stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "#                             rate=RATE, input=True,input_device_index = index,\n",
    "#                             frames_per_buffer=CHUNK)\n",
    "#                 OUTPUT_FILENAME=filename\n",
    "#                 WAVE_OUTPUT_FILENAME=os.path.join(\"training_set\",OUTPUT_FILENAME)\n",
    "#                 trainedfilelist = open(\"training_set_addition.txt\", 'a')\n",
    "#                 trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "#                 waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#                 waveFile.setnchannels(CHANNELS)\n",
    "#                 print(audio)\n",
    "#                 waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#                 waveFile.setframerate(RATE)\n",
    "#                 waveFile.writeframes(b''.join(Recordframes))\n",
    "#                 waveFile.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9540d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(\"C:\\\\Users\\\\Swati\\\\Desktop\\\\Cloud strats\\\\Gmm model\\\\training_set\"):\n",
    "    for filename in filenames:\n",
    "        trainedfilelist = open(\"training_set_addition.txt\", 'a')\n",
    "        trainedfilelist.write(filename+\"\\n\")\n",
    "        trainedfilelist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427504b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "\n",
    "    source = r\"C:\\\\Users\\\\Swati\\\\Desktop\\\\Cloud strats\\\\Gmm model\\\\training_set\\\\\" \n",
    "    dest = r\"C:\\Users\\Swati\\Desktop\\Cloud strats\\Gmm model\\trained_model\\\\\"\n",
    "    train_file = r\"C:\\Users\\Swati\\Desktop\\Cloud strats\\Gmm model\\\\training_set_addition.txt\"\n",
    "    assert os.path.isfile(train_file)\n",
    "    file_paths = open(train_file,'r')\n",
    "    count = 1\n",
    "    features = np.asarray(())\n",
    "    for path in file_paths:    \n",
    "        path = path.strip()   \n",
    "        print(path)\n",
    "\n",
    "        sr,audio = read(source + path)\n",
    "        print(sr)\n",
    "        vector   = extract_features(audio,sr)\n",
    "        \n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "            1\n",
    "        if count == 30: \n",
    "            gmm = GaussianMixture(n_components = 6, max_iter = 200, covariance_type='diag',n_init = 3)\n",
    "            gmm.fit(features)\n",
    "            \n",
    "            # dumping the trained gaussian model\n",
    "            picklefile = path.split(\"-\")[0]+\".gmm\"\n",
    "            pickle.dump(gmm,open(dest + picklefile,'wb'))\n",
    "            print('+ modeling completed for speaker:',picklefile,\" with data point = \",features.shape)   \n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84711388",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(\"C:\\\\Users\\\\Swati\\\\Desktop\\\\Cloud strats\\\\Gmm model\\\\testing_set\"):\n",
    "    for filename in filenames:\n",
    "        trainedfilelist = open(\"testing_set_addition.txt\", 'a')\n",
    "        trainedfilelist.write(filename+\"\\n\")\n",
    "        trainedfilelist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580b141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "        source   = r\"C:\\\\Users\\\\Swati\\\\Desktop\\\\Cloud strats\\\\Gmm model\\\\testing_set\\\\\"  \n",
    "        modelpath = r\"C:\\Users\\Swati\\Desktop\\Cloud strats\\Gmm model\\trained_model\\\\\"\n",
    "        test_file = r\"C:\\Users\\Swati\\Desktop\\Cloud strats\\Gmm model\\\\testing_set_addition.txt\"   \n",
    "        file_paths = open(test_file,'r')\n",
    "\n",
    "        gmm_files = [os.path.join(modelpath,fname) for fname in os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "        \n",
    "        #Load the Gaussian gender Models\n",
    "        models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "        speakers   = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname in gmm_files]\n",
    "        \n",
    "        \n",
    "        # Read the test directory and get the list of test audio files \n",
    "        for path in file_paths:   \n",
    "\n",
    "            path = path.strip()   \n",
    "#             print(path)\n",
    "            sr,audio = read(source + path)\n",
    "            vector   = extract_features(audio,sr)\n",
    "\n",
    "            \n",
    "            log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "            for i in range(len(models)):\n",
    "                gmm    = models[i]  #checking with each model one by one\n",
    "                scores = np.array(gmm.score(vector))\n",
    "                log_likelihood[i] = scores.sum()\n",
    "                \n",
    "\n",
    "            winner = np.argmax(log_likelihood)\n",
    "            print(\"\\tdetected as - \", speakers[\n",
    "                winner])\n",
    "            time.sleep(1.0) \n",
    "#     except ValueError:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afe70508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " 1.Train Dataset \n",
      " 2.Record audio for testing \n",
      " 3.Test Model\n",
      "1\n",
      "desktop.ini\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File format b'[Loc' not understood. Only 'RIFF' and 'RIFX' supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m choice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 1.Train Dataset \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 2.Record audio for testing \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m 3.Test Model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(choice\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(choice\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      6\u001b[0m     record_audio_test()\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mstrip()   \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[1;32m---> 14\u001b[0m sr,audio \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(sr)\n\u001b[0;32m     16\u001b[0m vector   \u001b[38;5;241m=\u001b[39m extract_features(audio,sr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\io\\wavfile.py:650\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m \u001b[43m_read_riff_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     fmt_chunk_received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    652\u001b[0m     data_chunk_received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\io\\wavfile.py:521\u001b[0m, in \u001b[0;36m_read_riff_chunk\u001b[1;34m(fid)\u001b[0m\n\u001b[0;32m    518\u001b[0m     fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>I\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;66;03m# There are also .wav files with \"FFIR\" or \"XFIR\" signatures?\u001b[39;00m\n\u001b[1;32m--> 521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(str1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not understood. Only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRIFX\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# Size of entire file\u001b[39;00m\n\u001b[0;32m    525\u001b[0m file_size \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(fmt, fid\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4\u001b[39m))[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m8\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: File format b'[Loc' not understood. Only 'RIFF' and 'RIFX' supported."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    choice=int(input(\" \\n 1.Train Dataset \\n 2.Record audio for testing \\n 3.Test Model\\n\"))\n",
    "    if(choice==1):\n",
    "        train_model()\n",
    "    elif(choice==2):\n",
    "        record_audio_test()\n",
    "    elif(choice==3):\n",
    "        test_model()\n",
    "        \n",
    "    if(choice>3):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24b6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0fef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51277f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c129d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4a6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
